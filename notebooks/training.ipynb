{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training\n",
    "(WiP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import graph_class as gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "import torch\n",
    "from torch import nn\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset = gc.WeatherDataset('test_one')\n",
    "dataset.create('../data/data_initial_preprocessing.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "g = dataset.graph\n",
    "g = dgl.add_self_loop(g)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Graph(num_nodes=667, num_edges=3540,\n      ndata_schemes={'x': Scheme(shape=(1393, 7), dtype=torch.float64), 'y': Scheme(shape=(1393,), dtype=torch.float64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n      edata_schemes={})"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#Classe da Rede Neural\n",
    "class CGN(nn.Module):\n",
    "    def __init__(self, in_feats, num_classes):\n",
    "        super(CGN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, 32, norm='both')\n",
    "        self.conv2 = GraphConv(32, 16, norm='both')\n",
    "        self.conv3 = GraphConv(16, num_classes, norm='both')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = torch.tanh(h)\n",
    "        h = self.conv2(g, h)\n",
    "        h = torch.tanh(h)\n",
    "        h = self.conv3(g, h)\n",
    "\n",
    "        return h"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "net = CGN(g.ndata['x'].shape[2], 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "CGN(\n  (conv1): GraphConv(in=7, out=32, normalization=both, activation=None)\n  (conv2): GraphConv(in=32, out=16, normalization=both, activation=None)\n  (conv3): GraphConv(in=16, out=1, normalization=both, activation=None)\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = net.float()\n",
    "net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "p = {\n",
    "    'epochs': 10000,\n",
    "    'optim': optim.Adam,\n",
    "    'loss_function': nn.MSELoss(),\n",
    "    'lr': 1e-3\n",
    "}\n",
    "\n",
    "net = net.to('cuda')\n",
    "g = g.to('cuda')\n",
    "name = 'runs/test_3'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 1.0068614482879639 Val Loss: 0.9212799072265625\n",
      "Epoch: 100 Loss: 0.9448891282081604 Val Loss: 0.8730277419090271\n",
      "Epoch: 200 Loss: 0.9438853859901428 Val Loss: 0.8722531795501709\n",
      "Epoch: 300 Loss: 0.9432968497276306 Val Loss: 0.871872067451477\n",
      "Epoch: 400 Loss: 0.9427592754364014 Val Loss: 0.8715268969535828\n",
      "Epoch: 500 Loss: 0.9421452879905701 Val Loss: 0.8711426854133606\n",
      "Epoch: 600 Loss: 0.9413684606552124 Val Loss: 0.8706011772155762\n",
      "Epoch: 700 Loss: 0.9403302073478699 Val Loss: 0.8698210120201111\n",
      "Epoch: 800 Loss: 0.9389535188674927 Val Loss: 0.86882483959198\n",
      "Epoch: 900 Loss: 0.9372388124465942 Val Loss: 0.8677184581756592\n",
      "Epoch: 1000 Loss: 0.9351782202720642 Val Loss: 0.8665796518325806\n",
      "Epoch: 1100 Loss: 0.9327078461647034 Val Loss: 0.8657634854316711\n",
      "Epoch: 1200 Loss: 0.9298631548881531 Val Loss: 0.8651872873306274\n",
      "Epoch: 1300 Loss: 0.9268057346343994 Val Loss: 0.8642699718475342\n",
      "Epoch: 1400 Loss: 0.9233274459838867 Val Loss: 0.862850546836853\n",
      "Epoch: 1500 Loss: 0.9200266599655151 Val Loss: 0.8624687194824219\n",
      "Epoch: 1600 Loss: 0.9169529676437378 Val Loss: 0.8614410161972046\n",
      "Epoch: 1700 Loss: 0.9143602848052979 Val Loss: 0.8618986010551453\n",
      "Epoch: 1800 Loss: 0.9122105240821838 Val Loss: 0.8624796271324158\n",
      "Epoch: 1900 Loss: 0.9104348421096802 Val Loss: 0.8633738160133362\n",
      "Epoch: 2000 Loss: 0.9088950753211975 Val Loss: 0.8644827604293823\n",
      "Epoch: 2100 Loss: 0.9075079560279846 Val Loss: 0.866058886051178\n",
      "Epoch: 2200 Loss: 0.9062045216560364 Val Loss: 0.8669523000717163\n",
      "Epoch: 2300 Loss: 0.9048722982406616 Val Loss: 0.8692055940628052\n",
      "Epoch: 2400 Loss: 0.9034523367881775 Val Loss: 0.8707732558250427\n",
      "Epoch: 2500 Loss: 0.901999294757843 Val Loss: 0.8729667067527771\n",
      "Epoch: 2600 Loss: 0.90058833360672 Val Loss: 0.8747817873954773\n",
      "Epoch: 2700 Loss: 0.8992144465446472 Val Loss: 0.876192569732666\n",
      "Epoch: 2800 Loss: 0.8978719711303711 Val Loss: 0.8777928352355957\n",
      "Epoch: 2900 Loss: 0.8965516090393066 Val Loss: 0.878999650478363\n",
      "Epoch: 3000 Loss: 0.8952262997627258 Val Loss: 0.8811818957328796\n",
      "Epoch: 3100 Loss: 0.8939924240112305 Val Loss: 0.8819918036460876\n",
      "Epoch: 3200 Loss: 0.8926556706428528 Val Loss: 0.8838555216789246\n",
      "Epoch: 3300 Loss: 0.8914527297019958 Val Loss: 0.8871329426765442\n",
      "Epoch: 3400 Loss: 0.8901433348655701 Val Loss: 0.8881409168243408\n",
      "Epoch: 3500 Loss: 0.8890760540962219 Val Loss: 0.8888073563575745\n",
      "Epoch: 3600 Loss: 0.8877856135368347 Val Loss: 0.8923290371894836\n",
      "Epoch: 3700 Loss: 0.8866443634033203 Val Loss: 0.8936790227890015\n",
      "Epoch: 3800 Loss: 0.8855770826339722 Val Loss: 0.8955389857292175\n",
      "Epoch: 3900 Loss: 0.8845388293266296 Val Loss: 0.897700846195221\n",
      "Epoch: 4000 Loss: 0.8835457563400269 Val Loss: 0.8997101187705994\n",
      "Epoch: 4100 Loss: 0.882601261138916 Val Loss: 0.9016154408454895\n",
      "Epoch: 4200 Loss: 0.8816888928413391 Val Loss: 0.9033821821212769\n",
      "Epoch: 4300 Loss: 0.8808081746101379 Val Loss: 0.9051529765129089\n",
      "Epoch: 4400 Loss: 0.8799461722373962 Val Loss: 0.9069293141365051\n",
      "Epoch: 4500 Loss: 0.8791124820709229 Val Loss: 0.9084056615829468\n",
      "Epoch: 4600 Loss: 0.8782895803451538 Val Loss: 0.9095132350921631\n",
      "Epoch: 4700 Loss: 0.8774909377098083 Val Loss: 0.9111297726631165\n",
      "Epoch: 4800 Loss: 0.8766353130340576 Val Loss: 0.9121770858764648\n",
      "Epoch: 4900 Loss: 0.8758199214935303 Val Loss: 0.9133595824241638\n",
      "Epoch: 5000 Loss: 0.8749946355819702 Val Loss: 0.9143832325935364\n",
      "Epoch: 5100 Loss: 0.8741948008537292 Val Loss: 0.9151709079742432\n",
      "Epoch: 5200 Loss: 0.8734089732170105 Val Loss: 0.9159895777702332\n",
      "Epoch: 5300 Loss: 0.872574508190155 Val Loss: 0.9173170924186707\n",
      "Epoch: 5400 Loss: 0.8717920780181885 Val Loss: 0.9183779954910278\n",
      "Epoch: 5500 Loss: 0.8710296750068665 Val Loss: 0.9192338585853577\n",
      "Epoch: 5600 Loss: 0.8702855110168457 Val Loss: 0.9201021790504456\n",
      "Epoch: 5700 Loss: 0.8695910573005676 Val Loss: 0.9214774966239929\n",
      "Epoch: 5800 Loss: 0.8688488602638245 Val Loss: 0.9217337965965271\n",
      "Epoch: 5900 Loss: 0.8681626915931702 Val Loss: 0.9225269556045532\n",
      "Epoch: 6000 Loss: 0.867494523525238 Val Loss: 0.923211395740509\n",
      "Epoch: 6100 Loss: 0.8668714165687561 Val Loss: 0.9247620701789856\n",
      "Epoch: 6200 Loss: 0.8661980032920837 Val Loss: 0.9246640801429749\n",
      "Epoch: 6300 Loss: 0.8655716776847839 Val Loss: 0.9252741932868958\n",
      "Epoch: 6400 Loss: 0.8649688959121704 Val Loss: 0.9258168935775757\n",
      "Epoch: 6500 Loss: 0.8643901348114014 Val Loss: 0.9260751008987427\n",
      "Epoch: 6600 Loss: 0.8640074729919434 Val Loss: 0.9257041811943054\n",
      "Epoch: 6700 Loss: 0.8632699847221375 Val Loss: 0.9271224141120911\n",
      "Epoch: 6800 Loss: 0.8627402782440186 Val Loss: 0.9276520609855652\n",
      "Epoch: 6900 Loss: 0.8622366786003113 Val Loss: 0.9275965690612793\n",
      "Epoch: 7000 Loss: 0.8617126941680908 Val Loss: 0.9280914068222046\n",
      "Epoch: 7100 Loss: 0.8612126111984253 Val Loss: 0.9282944202423096\n",
      "Epoch: 7200 Loss: 0.8607373833656311 Val Loss: 0.9285736680030823\n",
      "Epoch: 7300 Loss: 0.8602860569953918 Val Loss: 0.9283315539360046\n",
      "Epoch: 7400 Loss: 0.8597944974899292 Val Loss: 0.9290192723274231\n",
      "Epoch: 7500 Loss: 0.8593407869338989 Val Loss: 0.9293814301490784\n",
      "Epoch: 7600 Loss: 0.8588952422142029 Val Loss: 0.9297749400138855\n",
      "Epoch: 7700 Loss: 0.8584628105163574 Val Loss: 0.9299998879432678\n",
      "Epoch: 7800 Loss: 0.858039915561676 Val Loss: 0.9303421378135681\n",
      "Epoch: 7900 Loss: 0.8576250672340393 Val Loss: 0.9306721091270447\n",
      "Epoch: 8000 Loss: 0.8572148680686951 Val Loss: 0.9310084581375122\n",
      "Epoch: 8100 Loss: 0.856803834438324 Val Loss: 0.9314752221107483\n",
      "Epoch: 8200 Loss: 0.8564204573631287 Val Loss: 0.9319032430648804\n",
      "Epoch: 8300 Loss: 0.8560616970062256 Val Loss: 0.9322928786277771\n",
      "Epoch: 8400 Loss: 0.8556318283081055 Val Loss: 0.9330892562866211\n",
      "Epoch: 8500 Loss: 0.8552533388137817 Val Loss: 0.9334896802902222\n",
      "Epoch: 8600 Loss: 0.8548727631568909 Val Loss: 0.9339141845703125\n",
      "Epoch: 8700 Loss: 0.8544966578483582 Val Loss: 0.9344217777252197\n",
      "Epoch: 8800 Loss: 0.8541303277015686 Val Loss: 0.9352775812149048\n",
      "Epoch: 8900 Loss: 0.8537467122077942 Val Loss: 0.9355926513671875\n",
      "Epoch: 9000 Loss: 0.8533729314804077 Val Loss: 0.9360834360122681\n",
      "Epoch: 9100 Loss: 0.8529984354972839 Val Loss: 0.9366942644119263\n",
      "Epoch: 9200 Loss: 0.8526262044906616 Val Loss: 0.9372904896736145\n",
      "Epoch: 9300 Loss: 0.8522557616233826 Val Loss: 0.9380783438682556\n",
      "Epoch: 9400 Loss: 0.8518785238265991 Val Loss: 0.9385294318199158\n",
      "Epoch: 9500 Loss: 0.851507306098938 Val Loss: 0.9391433000564575\n",
      "Epoch: 9600 Loss: 0.8511244654655457 Val Loss: 0.9398511052131653\n",
      "Epoch: 9700 Loss: 0.8507476449012756 Val Loss: 0.9406546354293823\n",
      "Epoch: 9800 Loss: 0.8503612875938416 Val Loss: 0.941321611404419\n",
      "Epoch: 9900 Loss: 0.8499725461006165 Val Loss: 0.942049503326416\n",
      "Epoch: 9999 Loss: 0.8495960235595703 Val Loss: 0.9432745575904846\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(f\"{name}\")\n",
    "\n",
    "features = g.ndata['x'].float()\n",
    "label = g.ndata['y'].float()\n",
    "\n",
    "train_mask = g.ndata['train_mask']\n",
    "val_mask = g.ndata['val_mask']\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=p['lr'])\n",
    "\n",
    "history = {\n",
    "    'loss': [],\n",
    "    'val_loss': []\n",
    "}\n",
    "\n",
    "for epoch in range(p['epochs']):\n",
    "    prediction = net(g, features)\n",
    "    prediction = prediction.reshape(prediction.shape[0], prediction.shape[1])\n",
    "\n",
    "    loss = loss_fn(prediction[train_mask], label[train_mask])\n",
    "    val_loss = loss_fn(prediction[val_mask], label[val_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    history['loss'].append(loss.cpu().detach().numpy())\n",
    "    history['val_loss'].append(val_loss.cpu().detach().numpy())\n",
    "\n",
    "    writer.add_scalar(\"Loss/train\", loss, epoch) #tensorboard\n",
    "    writer.add_scalar(\"Loss/Val\", val_loss, epoch) #tensorboard\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch} Loss: {loss} Val Loss: {val_loss}')\n",
    "print(f'Epoch: {epoch} Loss: {loss} Val Loss: {val_loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,1393)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_8143/880947083.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscaler_y\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minverse_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0.94327\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documentos/mestrado/tese/github/msc_postprocessing_weather/venv/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001B[0m in \u001B[0;36minverse_transform\u001B[0;34m(self, X, copy)\u001B[0m\n\u001B[1;32m   1033\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1034\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_std\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1035\u001B[0;31m                 \u001B[0mX\u001B[0m \u001B[0;34m*=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscale_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1036\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_mean\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1037\u001B[0m                 \u001B[0mX\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,1393)"
     ]
    }
   ],
   "source": [
    "dataset.scaler_y.inverse_transform(np.array([0.94327]).reshape(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([533, 1400])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[train_mask].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[11.39190968,  7.16351918,  5.75264139, ..., 15.19342615,\n        15.11701595, 15.01706286]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.scaler_y.inverse_transform(np.repeat(np.array(1.069), 1400).reshape(-1, 1400))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "StandardScaler()"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "s = StandardScaler()\n",
    "teste = np.array([1,2,1,4,8,1,0,4,-2]).reshape(-1,1)\n",
    "s.fit(teste)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2.52693135]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.transform(np.array([9]).reshape(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}